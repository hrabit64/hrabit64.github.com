---
title: 유니티 ML_Agents 공부해보기 - 기본구조(2) Brain
categories: ML_Agents
tags: [ML_Agents,Unity]
toc: true
toc_label: 목차
toc_sticky: true
classes: wide
---



## 0. 개요

지난번에는 주인공 **에이전트**에 대해서 알아봤다면 이번에는 **브레인**에 대해서 알아볼 것이다.

브레인은 유니티 블로그에서는 다음과 같이 설명하고 있다.

***"각 브레인은 특정 상태와 행동 공간을 정의하고, 연결된 에이전트가 어떤 행동을 취할지 결정합니다."***

브레인은 현재 릴리즈를 기점으로 총 4가지 모드를 지원한다.



마찬가지로 유니티 블로그에서는 다음과 같이 설명하고 있다.

● **External** : ML 라이브러리를 사용하여 파이썬 api를 통해 개방형 소켓으로 통신하여 행동을 결정함

● **Internal** :  Tensorflowsharp 를 통해 프로젝트에 탑재된 훈련된 모델을 활용하여 행동을 결정합니다.(현재 기준으로 실험적인 모드로 설명되어있다.)

● **Player** : 플레이어의 입력을 통해 행동을 결정힘

● **Heuristic** : 직접 코딩한 동작을 기반으로 행동을 결정함



다만 책에는 **Heuristic**,**Player**가 생성가능하고, 추가적으로 **Learning Brain**이 생성가능하다고 나와있는데 이 러닝브레인은 어떤 내용인지 뒤에서 알아보겠다.

이 Brain 들은 공통적으로 설정가능한 파라미터들이 있다. 하나하나 살펴보도록 하겠다.



## 1. Copy Brain Parameter from

이 파라미터는 간단하게 말해 **복사** 기능이다. 다른 브레인의 파라미터들을 복사해오고 싶을 때, 이 기능을 사용하면 간단하게 다른 브레인의 파라미터들을 복사해올 수 있다. 후에 본격적으로 제작에 들어가면 강화학습은 에이전트 한개만 훈련시키는 것이 아닌 여러 가지의 에이전트들을 훈련시키는 경우도 있는데, 각각의 브레인들을 힘들게 복붙하지 않아도 이 기능을 이용하면 간단하게 여러개의 브레인들을 생성할 수 있다.



## 2. Vector Observation

이 파라미터는 **Space Size**와 **Stacked Vectors**을 설정할 수 있는 파라미터이다. 각가 어떤 기능들을 하는지 살펴보도록 하겠다.



### 2-1. Space Size

Space size는 지난번 공부했던 CollectObservation 함수에서 AddVectorObs 함수를 이용해 입력해둔 수치적 관측의 수와 동일하게 설정해줘야하는 인자이다.

만약 5개의 수치적 관측을 주었다면, Space Size의 값은 5가 되어야 할것이다.



### 2-2. Stacked Vectors

Stacked Vectors는 앞에서 space size를 통해 설정한 수치적 관측의 수를 몇 개를 이어 붙일지 결정하는 값이다. 예를 들어 Space Size가 5이고 Stacked Vectors 인자로 3을 주었다면 크기가 최종적으로 15개인 벡터를 수치적 관측으로 사용하게 되는 것이다.  이렇게 수치적 관측을 누적해야하는 경우가 있는데, 대표적으로 공의 움직임을 파악할 때, 누적된 관측이 포함된다면 해당 공의 속도를 알아 낼 수 있을 것이다. Stacked Vectors 를 잘 활용한다면, 여러 스텝의 정보를 한꺼번에 전달하여 시간과 관련된 정보를 제공할 수 있다.



## 3. Visual Observation

관측에는 2가지 관측이 있다. 앞서 계속 알아봤던 수치적 관측과 시각적 관측이 존재하는데, 이 파라미터는 수치적 관측을 브레인에 추가하고, 크기와 색상을 결정할 수 있다.

CNN을 공부해봤다면 알 수 있겠지만, 이미지 데이터는 RGB로 총 3개의 층으로 구성된다. 다시말해 64*64 컬러 이미지는 (64,64,3)이 되겠지만, GrayScale 이미지는 컬러 채널이 1개이므로 (64,64,1)가 될것이다.



## 4. Vector Action

백터 액션은 파라미터 이름에서부터 느껴지겠지만 액션에 관한 파라미터이다. 액션은 앞에서 살펴봤다 싶이 이산적인 행동이냐, 연속적인 행동이냐 에 따라 설정법이 달라진다.

우선 공통적으로 Space Type을 이용해 어떤 종류의 액션인지 설정해줄 수 있다. 또한 Action Descriptions를 이용하면 각각의 브랜치,Space가 어떤 역할을 하는지 주석을 달아 줄 수도 있다.

우선 이산적인 행동에서는 브랜치의 개수를 지정해주고, 각각의 브랜치의 크기를 지정해주면 된다.

연속적인 행동에서는 Space의 크기만 지정해주면 된다.



## 5. 플레이어 브레인

앞서 살펴본 브레인의 종류 중에 플레이어 브레인이 있었다. 이 브레인은 각 액션에 대해 키보드 키를 할당해주면, 키를 누를 때 에이전트가 할당된 액션을 하는 방식이다. 이제 액션이 나오면 반사적으로 나오겠지만 역시 이산적이냐 연속적이냐에 따라서 작성 방식이 다르다.



### 5-1. 이산적인 행동

이산적인 행동에서는 **Discrete Player Actions**라는 파라미터가 활성화 된다. 앞서 설명한 백터액션 파라미터에서 브랜치를 선언해주었을 것이다. 

이제 이 파라미터를 이용하면 각각의 브랜치의 값에 키를 지정해줄 수 있다. Key에는 키보드 키를 할당해주고, Branch idx에는 어떤 브랜치 인지 값을 입력해주고, Value에는 그 브랜치의 어떤 값인지 입력해주면 된다.

 예를 들어 브랜치 0,1이가 있고, 브랜치 0에는 0,1이라는 값이 있으며 0이라는 값에 스페이스바를 할당했다고 가정하면, 해당 스페이스 바를 누르면 앞서 에이전트에서 소개했던 AgentAction 함수의  vectorAction[0]이 0이라는 값을 반환 할 것이다. 만약 수치를 다르게 입력해주고 싶다면 해당 vectorAction[0]에 반환되는 값을 조건문을 이용해 처리하면 될 것이다.



### 5-2. 연속적인 행동

연속적인 행동에서는 각각의 Space에 키를 할당해주면 된다. 할당된 key를 누르면 마찬가지로 vectorAction[idx] 의 값이 해당 Value 만큼 반환 될 것이다.



추가로 유니티의 Axis Continuous Player Action을 이용하면 더욱 간단하게 4축을 구현할 수도 있다.





## 6. 휴리스틱 브레인

휴리스틱 브레인은 앞서 설명했듯이 사람이 직접 코드에서 작성한 방식대로 에이전트를 제어하는 브레인이다. 



실제 3D볼 예제에 들어있는 코드이다.



```c#
using System.Collections.Generic;
using UnityEngine;
using MLAgents;

public class Ball3DDecision : Decision
{
    public float rotationSpeed = 2f;

    public override float[] Decide(
        List<float> vectorObs,
        List<Texture2D> visualObs,
        float reward,
        bool done,
        List<float> memory)
    {
        if (brainParameters.vectorActionSpaceType == SpaceType.continuous)
        {
            List<float> act = new List<float>();

            // state[5] is the velocity of the ball in the x orientation. 
            // We use this number to control the Platform's z axis rotation speed, 
            // so that the Platform is tilted in the x orientation correspondingly. 
            act.Add(vectorObs[5] * rotationSpeed);

            // state[7] is the velocity of the ball in the z orientation. 
            // We use this number to control the Platform's x axis rotation speed,  
            // so that the Platform is tilted in the z orientation correspondingly. 
            act.Add(-vectorObs[7] * rotationSpeed);

            return act.ToArray();
        }

        // If the vector action space type is discrete, then we don't do anything.     
        return new float[1] { 1f };
    }

    public override List<float> MakeMemory(
        List<float> vectorObs,
        List<Texture2D> visualObs,
        float reward,
        bool done,
        List<float> memory)
    {
        return new List<float>();
    }
}


```

우선 대표적으로 보이는 함수로는 **Decide()**, **MakeMemory()**가 존재한다.

### 6-1. Decide()

이 함수는 에이전트의 현재 상태, 보상 등을 입력받아 브레인에서 설정한 행동의 종류에 따라 알맞은 형태의 행동을 반환한다. 역시나 액션의 종류에 따라 반환하는 값이 다른데, 이산적인 행동에서는 브랜치 수만큼 배열을 반환하고, 각 브랜치는 설정된 수 만큼의 정수값으로 구성된 배열이다. 연속적인 행동에서는 설정된 행동의 갯수에 맞추어 실숫값으로 이뤄진 배열을 반환한다.

앞의 코드를 통해 살펴보자

```c#
    public override float[] Decide(
        List<float> vectorObs,
        List<Texture2D> visualObs,
        float reward,
        bool done,
        List<float> memory)
```

**vectorObs(수치적 관측),visualObs(시각적 관측),reward(보상),done(게임 종료 여부),memory(이전 기억이다. 뒤에서 후술.)**을 입력받는 모습을 볼 수 있다.

```c#
   if (brainParameters.vectorActionSpaceType == SpaceType.continuous)
        {
            List<float> act = new List<float>();

            // state[5] is the velocity of the ball in the x orientation. 
            // We use this number to control the Platform's z axis rotation speed, 
            // so that the Platform is tilted in the x orientation correspondingly. 
            act.Add(vectorObs[5] * rotationSpeed);

            // state[7] is the velocity of the ball in the z orientation. 
            // We use this number to control the Platform's x axis rotation speed,  
            // so that the Platform is tilted in the z orientation correspondingly. 
            act.Add(-vectorObs[7] * rotationSpeed);

            return act.ToArray();
        }
```

앞부분의 if문을 보면 이 액션의 종류는 continuous 인것을 알 수 있다.  이후 act.Add()를 통해 실숫값들을 act리스트에 넣고 이것을 반환하는 모습이다. 즉 실숫값 리스트에 어떤 행동을 해야할지 리스트를 만들고 전달한다고 유추해볼 수 있다.

### 6-2. MakeMemory()

이 함수는 현재 스탭의 정보(에이전트의 상태나 보상 등)을 메모리라는 이름의 (영어 단어 뜻 그대로 기억이다. 그 RAM이 아니라.)리스트에 담아 다음 스탭의 Decide() 함수에 전달한다. 이렇게 되면 Decide()에서는 이전 정보와 현재 정보를 종합하여 행동을 결정할 수 있게 된다.

이번에도 코드를 살펴보자.

```c#
    public override List<float> MakeMemory(
        List<float> vectorObs,
        List<Texture2D> visualObs,
        float reward,
        bool done,
        List<float> memory)
    {
        return new List<float>();
```

vectorObs(수치적 관측),visualObs(시각적 관측),reward(보상),done(게임 종료 여부),memory(기억)을 전달받는다. 아까 Decide()함수가 받는 인자와 동일한 값들이 보인다. 이러한 정보들을 종합하여 메모리 리스트로 반환하는 것이다. 다만 그냥 빈 리스트를 반환하는 모습인데, 어떤 이유인지는 모르겠지만 이 예제가 사용되는 강화학습 환경에서는 이전 정보가 요구되지 않는 모습이다. 이렇게 이전 정보가 요구되지 않을 때에는, 그냥 빈 리스트를 반환하면 된다.



## 7. 러닝 브레인

러닝 브레인은 학습을 시키거나 테스트를 하는 곳에서도 사용할 수 있는 다재다능한 친구이다. 아카데미라는 공부하지 않은 요소까지 요구하므로 패스하도록 하겠다.









